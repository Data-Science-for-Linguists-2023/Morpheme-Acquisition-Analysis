{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "--- \n",
    "`NEW CONTINUING` script from [data_curation_cont](../notebooks/data_curation_cont.ipynb) script. \n",
    "\n",
    "Data processing pipeline: \n",
    "- [`data_curation.ipynb`](../notebooks/data_curation.ipynb)\n",
    "- [`data_curation_cont.ipynb`](../notebooks/data_curation_cont.ipynb)\n",
    "-  `data_analysis.ipynb` << You are here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading required libraries\n",
    "import nltk, pickle, pprint, csv, re, pylangacq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# pretty printing for readability\n",
    "cp = pprint.PrettyPrinter(compact=True, sort_dicts=True)\n",
    "\n",
    "# loading data from last notebook\n",
    "Lcorpus = pickle.load(open(\"../data/Lcorpus_cont.pkl\", 'rb'))\n",
    "Ncorpus = pickle.load(open(\"../data/Ncorpus_cont.pkl\", 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to R. Brown (1973), the starting point of acquisition order research, the order of L1 acquisition of English morphemes is as follows: \n",
    "\n",
    "| Rank        | Morpheme    |\n",
    "| ----------- | ----------- |\n",
    "| 1   | Present progressive (*-ing*)    |\n",
    "| 2/3   | *in, on*       |\n",
    "| 4   | Plural (*-s*)  |\n",
    "| 5   | Past irregular      |\n",
    "| 6   | Possessive (*-'s*)   |\n",
    "| 7  | Uncontractible copula (*is, am, are*)   |\n",
    "| 8  | Articles (*a, the*)   |\n",
    "| 9   | Past regular (*-ed*)      |\n",
    "| 10   | Third person singular (*-s*)     |\n",
    "| 11   | Third person irregular     |\n",
    "| 12   | Uncontractible auxiliary (*is, am, are*)  |\n",
    "| 13  | Contractible copula  |\n",
    "| 14  | Contractible auxiliary   |\n",
    "\n",
    "This project will not analyze all of these, but I will attempt to cover most of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the analysis, I'll extract and count instances of particular morphemes from each text. First, I'll test this out on a single row using the present progressive (verb suffix *-ing*). The MOR annotation scheme for the TalkBank corpora can be found [here](https://talkbank.org/manuals/MOR.html#_Toc65933281)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>POS</th>\n",
       "      <th>Morphemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03\\03a.cha</td>\n",
       "      <td>11312/c-00020713-1</td>\n",
       "      <td>3;01</td>\n",
       "      <td>[., when, he's, sleeping, ,, ., and, his, frog...</td>\n",
       "      <td>[None, conj, pro:sub, aux, part, cm, ., coord,...</td>\n",
       "      <td>[None, when, he, be&amp;3S, sleep-PRESP, cm, , and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename         Participant   Age  \\\n",
       "0  03\\03a.cha  11312/c-00020713-1  3;01   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [., when, he's, sleeping, ,, ., and, his, frog...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [None, conj, pro:sub, aux, part, cm, ., coord,...   \n",
       "\n",
       "                                           Morphemes  \n",
       "0  [None, when, he, be&3S, sleep-PRESP, cm, , and...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ncorpus.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep-PRESP', 'get-PRESP', 'stand-PRESP', 'run-PRESP'] \n",
      "count: 4\n"
     ]
    }
   ],
   "source": [
    "# -PRESP is the TalkBank MOR annotation for a verb in the present progressive\n",
    "pattern = r'\\w*-PRESP\\b'\n",
    "# sample row\n",
    "presp_test = Ncorpus.Morphemes[0]\n",
    "# find all present progressive morphemes\n",
    "presps = re.findall(pattern, ' '.join(str(x) for x in presp_test))\n",
    "print(presps, '\\ncount:', len(presps))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first participant in our data frame, age 3 years and 1 month, used the present progressive 4 times: 'sleeping', 'getting', 'standing', and 'running'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to define a function and get this information for the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_presp(x):\n",
    "    pattern = r'\\w*-PRESP\\b'\n",
    "    presps = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return presps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>POS</th>\n",
       "      <th>Morphemes</th>\n",
       "      <th>PresP_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03\\03a.cha</td>\n",
       "      <td>11312/c-00020713-1</td>\n",
       "      <td>3;01</td>\n",
       "      <td>[., when, he's, sleeping, ,, ., and, his, frog...</td>\n",
       "      <td>[None, conj, pro:sub, aux, part, cm, ., coord,...</td>\n",
       "      <td>[None, when, he, be&amp;3S, sleep-PRESP, cm, , and...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03\\03b.cha</td>\n",
       "      <td>11312/c-00020714-1</td>\n",
       "      <td>3;04</td>\n",
       "      <td>[they're, looking, at, it, ., and, there's, a,...</td>\n",
       "      <td>[pro:sub, aux, part, prep, pro:per, ., coord, ...</td>\n",
       "      <td>[they, be&amp;PRES, look-PRESP, at, it, , and, the...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03\\03c.cha</td>\n",
       "      <td>11312/c-00020715-1</td>\n",
       "      <td>3;04</td>\n",
       "      <td>[there's, a, frog, in, there, ., he's, in, the...</td>\n",
       "      <td>[pro:exist, cop, det:art, n, prep, adv, ., pro...</td>\n",
       "      <td>[there, be&amp;3S, a, frog, in, there, , he, be&amp;3S...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03\\03d.cha</td>\n",
       "      <td>11312/c-00020716-1</td>\n",
       "      <td>3;05</td>\n",
       "      <td>[a, frog, a, person, ., a, person, ., a, boot,...</td>\n",
       "      <td>[det:art, n, det:art, n, ., det:art, n, ., det...</td>\n",
       "      <td>[a, frog, a, person, , a, person, , a, boot, ,...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03\\03e.cha</td>\n",
       "      <td>11312/c-00020717-1</td>\n",
       "      <td>3;08</td>\n",
       "      <td>[., there's, a, dog, ., and, there's, a, frog,...</td>\n",
       "      <td>[None, pro:exist, cop, det:art, n, ., coord, p...</td>\n",
       "      <td>[None, there, be&amp;3S, a, dog, , and, there, be&amp;...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename         Participant   Age  \\\n",
       "0  03\\03a.cha  11312/c-00020713-1  3;01   \n",
       "1  03\\03b.cha  11312/c-00020714-1  3;04   \n",
       "2  03\\03c.cha  11312/c-00020715-1  3;04   \n",
       "3  03\\03d.cha  11312/c-00020716-1  3;05   \n",
       "4  03\\03e.cha  11312/c-00020717-1  3;08   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [., when, he's, sleeping, ,, ., and, his, frog...   \n",
       "1  [they're, looking, at, it, ., and, there's, a,...   \n",
       "2  [there's, a, frog, in, there, ., he's, in, the...   \n",
       "3  [a, frog, a, person, ., a, person, ., a, boot,...   \n",
       "4  [., there's, a, dog, ., and, there's, a, frog,...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [None, conj, pro:sub, aux, part, cm, ., coord,...   \n",
       "1  [pro:sub, aux, part, prep, pro:per, ., coord, ...   \n",
       "2  [pro:exist, cop, det:art, n, prep, adv, ., pro...   \n",
       "3  [det:art, n, det:art, n, ., det:art, n, ., det...   \n",
       "4  [None, pro:exist, cop, det:art, n, ., coord, p...   \n",
       "\n",
       "                                           Morphemes  PresP_Count  \n",
       "0  [None, when, he, be&3S, sleep-PRESP, cm, , and...            4  \n",
       "1  [they, be&PRES, look-PRESP, at, it, , and, the...            6  \n",
       "2  [there, be&3S, a, frog, in, there, , he, be&3S...            8  \n",
       "3  [a, frog, a, person, , a, person, , a, boot, ,...           23  \n",
       "4  [None, there, be&3S, a, dog, , and, there, be&...            3  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# native speaker corpus \n",
    "Ncorpus['PresP_Count'] = Ncorpus.Morphemes.apply(get_presp).str.len()\n",
    "Ncorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Anon_ID</th>\n",
       "      <th>L1</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years_Learn</th>\n",
       "      <th>Years_Env</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>POS</th>\n",
       "      <th>Morphemes</th>\n",
       "      <th>PresP_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vercellotti\\1060_3G1.cha</td>\n",
       "      <td>1060</td>\n",
       "      <td>fm5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>19.0</td>\n",
       "      <td>level4</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>[my, topic, is, describe, your, favorite, meal...</td>\n",
       "      <td>[det:poss, n, cop, v, det:poss, adj, n, prep, ...</td>\n",
       "      <td>[my, topic, be&amp;3S, describe, your, favorite, m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vercellotti\\1060_3G2.cha</td>\n",
       "      <td>1060</td>\n",
       "      <td>fm5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>19.0</td>\n",
       "      <td>level4</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>[the, topic, is, transportation, ., in, this, ...</td>\n",
       "      <td>[det:art, n, cop, n, ., prep, det:dem, n, qn, ...</td>\n",
       "      <td>[the, topic, be&amp;3S, transport&amp;dv-ATION, , in, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vercellotti\\1060_3G3.cha</td>\n",
       "      <td>1060</td>\n",
       "      <td>fm5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>19.0</td>\n",
       "      <td>level4</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>[the, topic, is, someone, I, admire, ., I'll, ...</td>\n",
       "      <td>[det:art, n, cop, pro:indef, pro:sub, v, ., pr...</td>\n",
       "      <td>[the, topic, be&amp;3S, someone, I, admire, , I, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vercellotti\\1060_4P1.cha</td>\n",
       "      <td>1060</td>\n",
       "      <td>fm5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>19.0</td>\n",
       "      <td>level4</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>[the, topic, is, talking, about, a, problem, i...</td>\n",
       "      <td>[det:art, n, aux, part, prep, det:art, n, prep...</td>\n",
       "      <td>[the, topic, be&amp;3S, talk-PRESP, about, a, prob...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vercellotti\\1060_4P2.cha</td>\n",
       "      <td>1060</td>\n",
       "      <td>fm5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>19.0</td>\n",
       "      <td>level4</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>[the, topic, is, talk, about, something, I, re...</td>\n",
       "      <td>[det:art, n, cop, v, adv, pro:indef, pro:sub, ...</td>\n",
       "      <td>[the, topic, be&amp;3S, talk, about, something, I,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Filename Participant Anon_ID      L1   Age Education  \\\n",
       "0  Vercellotti\\1060_3G1.cha        1060     fm5  Arabic  19.0    level4   \n",
       "1  Vercellotti\\1060_3G2.cha        1060     fm5  Arabic  19.0    level4   \n",
       "2  Vercellotti\\1060_3G3.cha        1060     fm5  Arabic  19.0    level4   \n",
       "3  Vercellotti\\1060_4P1.cha        1060     fm5  Arabic  19.0    level4   \n",
       "4  Vercellotti\\1060_4P2.cha        1060     fm5  Arabic  19.0    level4   \n",
       "\n",
       "         Years_Learn         Years_Env  \\\n",
       "0  more than 5 years  less than 1 year   \n",
       "1  more than 5 years  less than 1 year   \n",
       "2  more than 5 years  less than 1 year   \n",
       "3  more than 5 years  less than 1 year   \n",
       "4  more than 5 years  less than 1 year   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [my, topic, is, describe, your, favorite, meal...   \n",
       "1  [the, topic, is, transportation, ., in, this, ...   \n",
       "2  [the, topic, is, someone, I, admire, ., I'll, ...   \n",
       "3  [the, topic, is, talking, about, a, problem, i...   \n",
       "4  [the, topic, is, talk, about, something, I, re...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [det:poss, n, cop, v, det:poss, adj, n, prep, ...   \n",
       "1  [det:art, n, cop, n, ., prep, det:dem, n, qn, ...   \n",
       "2  [det:art, n, cop, pro:indef, pro:sub, v, ., pr...   \n",
       "3  [det:art, n, aux, part, prep, det:art, n, prep...   \n",
       "4  [det:art, n, cop, v, adv, pro:indef, pro:sub, ...   \n",
       "\n",
       "                                           Morphemes  PresP_Count  \n",
       "0  [my, topic, be&3S, describe, your, favorite, m...            5  \n",
       "1  [the, topic, be&3S, transport&dv-ATION, , in, ...            0  \n",
       "2  [the, topic, be&3S, someone, I, admire, , I, w...            0  \n",
       "3  [the, topic, be&3S, talk-PRESP, about, a, prob...            4  \n",
       "4  [the, topic, be&3S, talk, about, something, I,...            3  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learner corpus\n",
    "Lcorpus['PresP_Count'] = Lcorpus.Morphemes.apply(get_presp).str.len()\n",
    "Lcorpus.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for other important morphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in\n",
    "def get_in(x):\n",
    "    pattern = r'\\bin\\b'\n",
    "    ins = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return ins\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['In_Count'] = Ncorpus.Morphemes.apply(get_in).str.len()\n",
    "Lcorpus['In_Count'] = Lcorpus.Morphemes.apply(get_in).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on\n",
    "def get_on(x):\n",
    "    pattern = r'\\bon\\b'\n",
    "    ons = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return ons\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['On_Count'] = Ncorpus.Morphemes.apply(get_on).str.len()\n",
    "Lcorpus['On_Count'] = Lcorpus.Morphemes.apply(get_on).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# past irregular\n",
    "def get_pastirr(x):\n",
    "    pattern = r'\\w*&PAST\\b'\n",
    "    pastirr = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return pastirr\n",
    "# adding data to the data frames\n",
    "Ncorpus['PastIrr_Count'] = Ncorpus.Morphemes.apply(get_pastirr).str.len()\n",
    "Lcorpus['PastIrr_Count'] = Lcorpus.Morphemes.apply(get_pastirr).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possessives\n",
    "def get_poss(x):\n",
    "    pattern = r'\\w*-POSS\\b'\n",
    "    poss = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return poss\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['Poss_Count'] = Ncorpus.Morphemes.apply(get_poss).str.len()\n",
    "Lcorpus['Poss_Count'] = Lcorpus.Morphemes.apply(get_poss).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copula\n",
    "def get_cop(x):\n",
    "    pattern = r'cop'\n",
    "    cops = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return cops\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['Cop_Count'] = Ncorpus.POS.apply(get_cop).str.len()\n",
    "Lcorpus['Cop_Count'] = Lcorpus.POS.apply(get_cop).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles\n",
    "def get_art(x):\n",
    "    pattern = r'det:art'\n",
    "    arts = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return arts\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['Art_Count'] = Ncorpus.POS.apply(get_art).str.len()\n",
    "Lcorpus['Art_Count'] = Lcorpus.POS.apply(get_art).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# past regular\n",
    "def get_pastreg(x):\n",
    "    pattern = r'\\w*-PAST\\b'\n",
    "    pastreg = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return pastreg\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['PastReg_Count'] = Ncorpus.Morphemes.apply(get_pastreg).str.len()\n",
    "Lcorpus['PastReg_Count'] = Lcorpus.Morphemes.apply(get_pastreg).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third person singular\n",
    "def get_tps(x):\n",
    "    pattern = r'\\w*-3S\\b'\n",
    "    tps = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return tps\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['3PS_Count'] = Ncorpus.Morphemes.apply(get_tps).str.len()\n",
    "Lcorpus['3PS_Count'] = Lcorpus.Morphemes.apply(get_tps).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third person irregular\n",
    "def get_tpirr(x):\n",
    "    pattern = r'\\w*&3S\\b' \n",
    "    tpirr = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return tpirr\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['3PIrr_Count'] = Ncorpus.Morphemes.apply(get_tpirr).str.len()\n",
    "Lcorpus['3PIrr_Count'] = Lcorpus.Morphemes.apply(get_tpirr).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary\n",
    "def get_aux(x):\n",
    "    pattern = r'aux'\n",
    "    aux = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return aux\n",
    "\n",
    "# adding data to the data frames\n",
    "Ncorpus['Aux_Count'] = Ncorpus.POS.apply(get_aux).str.len()\n",
    "Lcorpus['Aux_Count'] = Lcorpus.POS.apply(get_aux).str.len()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morpheme counting completed. Morpheme counts alone are also not necessarily informative. These values need to be normalized so that they are not affected by other factors such as length of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token counts\n",
    "Ncorpus['Token_Count'] = Ncorpus['Tokens'].str.len()\n",
    "Lcorpus['Token_Count'] = Lcorpus['Tokens'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing counts\n",
    "Lcorpus[['PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']] = Lcorpus[['PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']].div(Lcorpus.Token_Count, axis=0)\n",
    "Ncorpus[['PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']] = Ncorpus[['PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']].div(Ncorpus.Token_Count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PresP_Count</th>\n",
       "      <th>In_Count</th>\n",
       "      <th>On_Count</th>\n",
       "      <th>PastIrr_Count</th>\n",
       "      <th>Poss_Count</th>\n",
       "      <th>Cop_Count</th>\n",
       "      <th>Art_Count</th>\n",
       "      <th>PastReg_Count</th>\n",
       "      <th>3PS_Count</th>\n",
       "      <th>3PIrr_Count</th>\n",
       "      <th>Aux_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3.01</th>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.04</th>\n",
       "      <td>0.070827</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.042571</td>\n",
       "      <td>0.075646</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061190</td>\n",
       "      <td>0.026432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.05</th>\n",
       "      <td>0.064789</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.08</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.09</th>\n",
       "      <td>0.041602</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.102091</td>\n",
       "      <td>0.023606</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.039330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.10</th>\n",
       "      <td>0.052163</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.132692</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.060096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.11</th>\n",
       "      <td>0.042180</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>0.069399</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.104319</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.04</th>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.070485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.154185</td>\n",
       "      <td>0.048458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.06</th>\n",
       "      <td>0.023090</td>\n",
       "      <td>0.025822</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.084395</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.031287</td>\n",
       "      <td>0.028054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.07</th>\n",
       "      <td>0.045849</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.043219</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.082435</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.031783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.08</th>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.051613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.09</th>\n",
       "      <td>0.022723</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.064836</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.10</th>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.11</th>\n",
       "      <td>0.070064</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.082803</td>\n",
       "      <td>0.076433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.01</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.02</th>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.076586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>0.120350</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.03</th>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.082734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.133094</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.06</th>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.020548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.08</th>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.076115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.131234</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.028871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.09</th>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.047264</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.10</th>\n",
       "      <td>0.034645</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.037372</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>0.132475</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.045398</td>\n",
       "      <td>0.041884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.11</th>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.066484</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.024569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.01</th>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>0.115819</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.03</th>\n",
       "      <td>0.035587</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.117438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064057</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>0.032028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.06</th>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.050663</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.011358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.07</th>\n",
       "      <td>0.032178</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.101485</td>\n",
       "      <td>0.032178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.08</th>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.066282</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.121037</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.09</th>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011349</td>\n",
       "      <td>0.130590</td>\n",
       "      <td>0.034048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.016952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.10</th>\n",
       "      <td>0.031161</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.141643</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.031161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.11</th>\n",
       "      <td>0.029748</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.031548</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.091432</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>0.030035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.00</th>\n",
       "      <td>0.027286</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.135723</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.036848</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.027775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PresP_Count  In_Count  On_Count  PastIrr_Count  Poss_Count  Cop_Count  \\\n",
       "Age                                                                            \n",
       "3.01      0.050633  0.000000  0.025316       0.050633    0.000000   0.012658   \n",
       "3.04      0.070827  0.031765  0.000000       0.007812    0.007812   0.042571   \n",
       "3.05      0.064789  0.014085  0.016901       0.033803    0.000000   0.033803   \n",
       "3.08      0.029412  0.039216  0.000000       0.039216    0.000000   0.058824   \n",
       "3.09      0.041602  0.013056  0.006287       0.023674    0.002174   0.018576   \n",
       "3.10      0.052163  0.022115  0.000000       0.017308    0.000000   0.018990   \n",
       "3.11      0.042180  0.025553  0.019456       0.069399    0.003049   0.011252   \n",
       "4.04      0.008811  0.013216  0.008811       0.070485    0.000000   0.022026   \n",
       "4.06      0.023090  0.025822  0.002232       0.020589    0.000000   0.014893   \n",
       "4.07      0.045849  0.014850  0.019097       0.043219    0.002625   0.020356   \n",
       "4.08      0.103226  0.019355  0.006452       0.012903    0.000000   0.012903   \n",
       "4.09      0.022723  0.004695  0.009390       0.047934    0.004695   0.010376   \n",
       "4.10      0.026549  0.000000  0.008850       0.070796    0.008850   0.026549   \n",
       "4.11      0.070064  0.006369  0.006369       0.012739    0.000000   0.019108   \n",
       "5.01      0.014493  0.014493  0.009662       0.019324    0.004831   0.038647   \n",
       "5.02      0.024070  0.017505  0.006565       0.076586    0.000000   0.013129   \n",
       "5.03      0.010791  0.003597  0.007194       0.082734    0.000000   0.028777   \n",
       "5.06      0.034247  0.027397  0.006849       0.034247    0.000000   0.047945   \n",
       "5.08      0.023622  0.005249  0.023622       0.076115    0.000000   0.010499   \n",
       "5.09      0.022388  0.014925  0.007463       0.002488    0.007463   0.019900   \n",
       "5.10      0.034645  0.016396  0.012464       0.037372    0.005228   0.021093   \n",
       "5.11      0.021556  0.016351  0.009725       0.066484    0.001592   0.013166   \n",
       "9.01      0.014124  0.014124  0.011299       0.093220    0.000000   0.019774   \n",
       "9.03      0.035587  0.021352  0.000000       0.000000    0.000000   0.021352   \n",
       "9.06      0.010405  0.004018  0.009452       0.050663    0.001416   0.010868   \n",
       "9.07      0.032178  0.004950  0.002475       0.081683    0.000000   0.019802   \n",
       "9.08      0.040346  0.011527  0.008646       0.066282    0.005764   0.002882   \n",
       "9.09      0.018425  0.018425  0.008512       0.076500    0.000000   0.011349   \n",
       "9.10      0.031161  0.016997  0.008499       0.079320    0.002833   0.008499   \n",
       "9.11      0.029748  0.007756  0.006768       0.031548    0.002373   0.018452   \n",
       "20.00     0.027286  0.018716  0.007067       0.020947    0.003012   0.018429   \n",
       "\n",
       "       Art_Count  PastReg_Count  3PS_Count  3PIrr_Count  Aux_Count  \n",
       "Age                                                                 \n",
       "3.01    0.063291       0.012658   0.000000     0.063291   0.037975  \n",
       "3.04    0.075646       0.007812   0.000000     0.061190   0.026432  \n",
       "3.05    0.118310       0.000000   0.005634     0.030986   0.028169  \n",
       "3.08    0.088235       0.009804   0.000000     0.098039   0.039216  \n",
       "3.09    0.102091       0.023606   0.002404     0.045664   0.039330  \n",
       "3.10    0.132692       0.012740   0.006250     0.066587   0.060096  \n",
       "3.11    0.104319       0.018293   0.000000     0.010309   0.008203  \n",
       "4.04    0.154185       0.048458   0.000000     0.004405   0.017621  \n",
       "4.06    0.084395       0.026786   0.016393     0.031287   0.028054  \n",
       "4.07    0.082435       0.025006   0.015748     0.034381   0.031783  \n",
       "4.08    0.129032       0.000000   0.012903     0.051613   0.051613  \n",
       "4.09    0.064836       0.026808   0.013333     0.003333   0.011362  \n",
       "4.10    0.168142       0.017699   0.017699     0.044248   0.026549  \n",
       "4.11    0.101911       0.000000   0.012739     0.082803   0.076433  \n",
       "5.01    0.072464       0.009662   0.033816     0.038647   0.014493  \n",
       "5.02    0.120350       0.030635   0.004376     0.000000   0.024070  \n",
       "5.03    0.133094       0.032374   0.000000     0.007194   0.003597  \n",
       "5.06    0.075342       0.000000   0.013699     0.054795   0.020548  \n",
       "5.08    0.131234       0.015748   0.013123     0.007874   0.028871  \n",
       "5.09    0.082090       0.002488   0.047264     0.049751   0.037313  \n",
       "5.10    0.132475       0.011552   0.021794     0.045398   0.041884  \n",
       "5.11    0.149917       0.022549   0.021812     0.011745   0.024569  \n",
       "9.01    0.115819       0.022599   0.000000     0.000000   0.011299  \n",
       "9.03    0.117438       0.000000   0.064057     0.039146   0.032028  \n",
       "9.06    0.142892       0.020142   0.036827     0.009915   0.011358  \n",
       "9.07    0.101485       0.032178   0.000000     0.009901   0.029703  \n",
       "9.08    0.121037       0.040346   0.002882     0.000000   0.011527  \n",
       "9.09    0.130590       0.034048   0.000000     0.002837   0.016952  \n",
       "9.10    0.141643       0.019830   0.011331     0.011331   0.031161  \n",
       "9.11    0.091432       0.013459   0.039130     0.022642   0.030035  \n",
       "20.00   0.135723       0.009563   0.036848     0.028455   0.027775  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 corpus\n",
    "Ncorpus['Age'] = Ncorpus['Age'].str.replace(';','.').astype(float)\n",
    "Ncorp_counts = Ncorpus[['Age', 'PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']].groupby(\"Age\").mean()\n",
    "Ncorp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PresP_Count</th>\n",
       "      <th>In_Count</th>\n",
       "      <th>On_Count</th>\n",
       "      <th>PastIrr_Count</th>\n",
       "      <th>Poss_Count</th>\n",
       "      <th>Cop_Count</th>\n",
       "      <th>Art_Count</th>\n",
       "      <th>PastReg_Count</th>\n",
       "      <th>3PS_Count</th>\n",
       "      <th>3PIrr_Count</th>\n",
       "      <th>Aux_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years_Learn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>less than 1 year</th>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.027361</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.041170</td>\n",
       "      <td>0.051258</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0.013034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-2 years</th>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.021712</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032253</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.013120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-5 years</th>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.055516</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.011308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more than 5 years</th>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.023746</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.012471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PresP_Count  In_Count  On_Count  PastIrr_Count  Poss_Count  \\\n",
       "Years_Learn                                                                     \n",
       "less than 1 year      0.012039  0.021260  0.000878       0.027361    0.000226   \n",
       "1-2 years             0.011227  0.021712  0.003009       0.021357    0.000000   \n",
       "3-5 years             0.012935  0.022241  0.000526       0.017896    0.000586   \n",
       "more than 5 years     0.012690  0.023746  0.003156       0.015538    0.000336   \n",
       "\n",
       "                   Cop_Count  Art_Count  PastReg_Count  3PS_Count  \\\n",
       "Years_Learn                                                         \n",
       "less than 1 year    0.041170   0.051258       0.009242   0.002192   \n",
       "1-2 years           0.032253   0.048732       0.006873   0.002880   \n",
       "3-5 years           0.041438   0.055516       0.005897   0.002357   \n",
       "more than 5 years   0.036640   0.061591       0.005599   0.004418   \n",
       "\n",
       "                   3PIrr_Count  Aux_Count  \n",
       "Years_Learn                                \n",
       "less than 1 year      0.028158   0.013034  \n",
       "1-2 years             0.025825   0.013120  \n",
       "3-5 years             0.033155   0.011308  \n",
       "more than 5 years     0.029697   0.012471  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 corpus\n",
    "Lcorpus['Years_Learn'] = pd.Categorical(Lcorpus['Years_Learn'],\n",
    "                                        ['less than 1 year', '1-2 years', '3-5 years',\n",
    "                                         'more than 5 years'])\n",
    "Lcorp_counts = Lcorpus[['Years_Learn', 'PresP_Count', 'In_Count', 'On_Count', 'PastIrr_Count', \n",
    "        'Poss_Count', 'Cop_Count', 'Art_Count', 'PastReg_Count', \n",
    "        '3PS_Count', '3PIrr_Count', 'Aux_Count']].groupby(\"Years_Learn\").mean()\n",
    "Lcorp_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data frames are not the easiest to parse. \n",
    "\n",
    "From a brief glance at the native speaker corpus, it appears that there are some patterns in the occurence of partiuclar morphemes that seem to increase with age through the proposed acquisition order. \n",
    "\n",
    "However, the learner corpus doesn't appear to demonstrate any similar pattern at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncorp_counts.to_csv(r'../data_samples/Ncorp_counts.csv', header=True)\n",
    "Lcorp_counts.to_csv(r'../data_samples/Lcorp_counts.csv', header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visualizations should also help make sense of this. To be continued."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
