{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data curation continued\n",
    "--- \n",
    "`NEW CONTINUING` script from the first [data_curation](../notebooks/data_curation.ipynb) script. \n",
    "\n",
    "Data processing pipeline: \n",
    "- [`data_curation.ipynb`](../notebooks/data_curation.ipynb)\n",
    "- `data_curation_cont.ipynb` <<\n",
    "\n",
    "__Script header__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading required libraries\n",
    "import nltk, pickle, pprint, csv, pylangacq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pretty printing for readability\n",
    "cp = pprint.PrettyPrinter(compact=True, sort_dicts=True)\n",
    "\n",
    "# loading data from last notebook\n",
    "Lcorpus = pickle.load(open(\"../data/Lcorpus.pkl\", 'rb'))\n",
    "Ncorpus = pickle.load(open(\"../data/Ncorpus.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Overview\n",
    "\n",
    "Continuing my data curation efforts after first [progress report](../progress_report.md). In the last notebook, some issues were encountered, namely, the learner corpus may not be appropriate/contain sufficient data for my analysis. Thus, my first step is to delve into more exploration of that data to see if it will suffice. Following this, I will begin to investigate specific morphemes that are salient in the texts.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>Age</th>\n",
       "      <th>L1</th>\n",
       "      <th>Age_Exposure</th>\n",
       "      <th>Years_Study</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE_SP_B1_26_13_13_TM</td>\n",
       "      <td>B1</td>\n",
       "      <td>26</td>\n",
       "      <td>German</td>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>One day Tommy found a frog in a forest and bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE_SP_B1_19_11_13_RN</td>\n",
       "      <td>B1</td>\n",
       "      <td>19</td>\n",
       "      <td>German</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>One day a little boy called John uh with his d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE_SP_B1_21_12_13_SE</td>\n",
       "      <td>B1</td>\n",
       "      <td>21</td>\n",
       "      <td>German</td>\n",
       "      <td>9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>One day a boy was sitting in his room / uh he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE_SP_B1_22_15_13_LF</td>\n",
       "      <td>B1</td>\n",
       "      <td>22</td>\n",
       "      <td>German</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Uh one day a little boy and his dog are watchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE_SP_B1_33_10_14_JR</td>\n",
       "      <td>B1</td>\n",
       "      <td>33</td>\n",
       "      <td>German</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ok this story is about toch uh Charles Chaplin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename Proficiency  Age      L1  Age_Exposure  Years_Study  \\\n",
       "0  DE_SP_B1_26_13_13_TM         B1    26  German             8         13.0   \n",
       "1  DE_SP_B1_19_11_13_RN         B1    19  German            10         11.0   \n",
       "2  DE_SP_B1_21_12_13_SE         B1    21  German             9         12.0   \n",
       "3  DE_SP_B1_22_15_13_LF         B1    22  German             7         15.0   \n",
       "4  DE_SP_B1_33_10_14_JR         B1    33  German            10         10.0   \n",
       "\n",
       "                                                Text  \n",
       "0  One day Tommy found a frog in a forest and bro...  \n",
       "1  One day a little boy called John uh with his d...  \n",
       "2  One day a boy was sitting in his room / uh he ...  \n",
       "3  Uh one day a little boy and his dog are watchi...  \n",
       "4  Ok this story is about toch uh Charles Chaplin...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lcorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "Lcorpus_7 = Lcorpus[Lcorpus.Years_Study <= 7]\n",
    "print(len(Lcorpus))\n",
    "print(len(Lcorpus_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 14 samples out of the 350 learners in this corpus that have been studying English for 7 years or less. Therefore, most data is from learners who are likely past the stages of acquisition where they would be acquiring basic morphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>Age</th>\n",
       "      <th>L1</th>\n",
       "      <th>Age_Exposure</th>\n",
       "      <th>Years_Study</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ES_SP_A2_50_6_14_MJRC</td>\n",
       "      <td>A2</td>\n",
       "      <td>50</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>uh well uh this video / this story is about uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ES_SP_A2_18_3_14_PAMM</td>\n",
       "      <td>A2</td>\n",
       "      <td>18</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hhh uh Charles Chaplin hhh was walking and smo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ES_SP_A2_19_2_13_ERO</td>\n",
       "      <td>A2</td>\n",
       "      <td>19</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>uh one day hhh they boy and her / his dog hhh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ES_SP_A2_26_3_14_SM</td>\n",
       "      <td>A2</td>\n",
       "      <td>26</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hi in this video we can look uh at a you can w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ES_SP_A2_23_4_14_B</td>\n",
       "      <td>A2</td>\n",
       "      <td>23</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>hello / my name is / ryan 'n' / 'n' this video...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filename Proficiency  Age       L1  Age_Exposure  \\\n",
       "180  ES_SP_A2_50_6_14_MJRC         A2    50  Spanish            38   \n",
       "181  ES_SP_A2_18_3_14_PAMM         A2    18  Spanish            15   \n",
       "182   ES_SP_A2_19_2_13_ERO         A2    19  Spanish            17   \n",
       "185    ES_SP_A2_26_3_14_SM         A2    26  Spanish            11   \n",
       "189     ES_SP_A2_23_4_14_B         A2    23  Spanish            16   \n",
       "\n",
       "     Years_Study                                               Text  \n",
       "180          6.0  uh well uh this video / this story is about uh...  \n",
       "181          3.0  hhh uh Charles Chaplin hhh was walking and smo...  \n",
       "182          2.0  uh one day hhh they boy and her / his dog hhh ...  \n",
       "185          3.0  hi in this video we can look uh at a you can w...  \n",
       "189          4.0  hello / my name is / ryan 'n' / 'n' this video...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lcorpus_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lcorpus_7.L1.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, they all share an L1, Spanish. This sample is not likely to provide an adequate amount of data for my analysis. It would also be restricted to a single L1, which isn't ideal for making generalizations about all English language learners, especially since Spanish is similar to English in quite a few aspects of morphology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan B: import new SLABank data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it would have been interesting to leverage two corpora sources for this analysis, the cons for CORFL were too substantial. It has proven challenging to find additional spoken, transcribed, English as an L2 corpora that are _freely_ available online, so I will resort to using additional corpora from the TalkBank family. \n",
    "\n",
    "These corpora come from SLABank rather than CHILDES. In addition, this time I will compile data from multiple corpora rather than a single one in order to include a variety of L1's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a sample of the data using `PyLangAcq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "path = '../data/SLABank/BELC'\n",
    "\n",
    "BELC_narr = pylangacq.read_chat(path, 'narratives') # creating a reader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pylangacq.chat.Reader'>\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print(type(BELC_narr))\n",
    "print(BELC_narr.n_files()) # info about this object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment': 'pronounced as /lif/',\n",
      " 'Languages': ['spa', 'cat', 'eng'],\n",
      " 'Media': '9139riza_1, audio, unlinked',\n",
      " 'PID': '11312/t-00016825-1',\n",
      " 'Participants': {'SUB': {'age': '10;09.00',\n",
      "                          'corpus': 'BELC',\n",
      "                          'custom': '',\n",
      "                          'education': '',\n",
      "                          'group': '1A',\n",
      "                          'language': 'eng',\n",
      "                          'name': '9139RIZA',\n",
      "                          'role': 'Subject',\n",
      "                          'ses': '',\n",
      "                          'sex': 'female'}},\n",
      " 'Transcriber': 'Mireia',\n",
      " 'UTF8': ''}\n"
     ]
    }
   ],
   "source": [
    "cp.pprint(BELC_narr.headers()[0]) # checking stored metadata for first CHAT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SUB': {'name': '9139RIZA',\n",
       "  'language': 'eng',\n",
       "  'corpus': 'BELC',\n",
       "  'age': '10;09.00',\n",
       "  'sex': 'female',\n",
       "  'group': '1A',\n",
       "  'ses': '',\n",
       "  'role': 'Subject',\n",
       "  'education': '',\n",
       "  'custom': ''}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BELC_narr.headers()[0]['Participants']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One major issue: there is no metadata stored about the _length of time the subject has spent learning English_ which is independent of age and crucial for my analysis. The `group` variable might be based on proficiency.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, according to the [author's introduction to the data](https://slabank.talkbank.org/access/English/BELC.html), groups do indeed to correlate to the age at which the subjects began instruction in English. This will be necessary, along with the age variable, in order to calculate years spent learning English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict= {}# dictionary to reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(word='okay', pos='co', mor='okay', gra=Gra(dep=1, head=2, rel='COM')),\n",
       " Token(word='hm', pos='phon', mor='hm', gra=Gra(dep=2, head=5, rel='LINK')),\n",
       " Token(word='the', pos='det:art', mor='the', gra=Gra(dep=3, head=4, rel='DET')),\n",
       " Token(word='story', pos='n', mor='story', gra=Gra(dep=4, head=5, rel='SUBJ')),\n",
       " Token(word='starts', pos='v', mor='start-3S', gra=Gra(dep=5, head=0, rel='ROOT')),\n",
       " Token(word='with', pos='prep', mor='with', gra=Gra(dep=6, head=5, rel='JCT')),\n",
       " Token(word='a', pos='det:art', mor='a', gra=Gra(dep=7, head=9, rel='DET')),\n",
       " Token(word='poor', pos='adj', mor='poor', gra=Gra(dep=8, head=9, rel='MOD')),\n",
       " Token(word='woman', pos='n', mor='woman', gra=Gra(dep=9, head=6, rel='POBJ')),\n",
       " Token(word='dressing', pos='part', mor='dress-PRESP', gra=Gra(dep=10, head=5, rel='XJCT')),\n",
       " Token(word='in', pos='prep', mor='in', gra=Gra(dep=11, head=10, rel='JCT')),\n",
       " Token(word='rucks', pos='neo', mor='rucks', gra=Gra(dep=12, head=11, rel='POBJ')),\n",
       " Token(word='and', pos='coord', mor='and', gra=Gra(dep=13, head=10, rel='CONJ')),\n",
       " Token(word='looking', pos='part', mor='look-PRESP', gra=Gra(dep=14, head=13, rel='COORD')),\n",
       " Token(word='at', pos='prep', mor='at', gra=Gra(dep=15, head=14, rel='JCT')),\n",
       " Token(word='a', pos='det:art', mor='a', gra=Gra(dep=16, head=15, rel='POBJ')),\n",
       " Token(word='//.', pos='+//.', mor='', gra=Gra(dep=17, head=5, rel='PUNCT')),\n",
       " Token(word='the', pos='det:art', mor='the', gra=Gra(dep=1, head=2, rel='DET')),\n",
       " Token(word='word', pos='n', mor='word', gra=Gra(dep=2, head=5, rel='SUBJ')),\n",
       " Token(word=\"doesn't\", pos='mod', mor='do&3S', gra=Gra(dep=3, head=5, rel='AUX'))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BELC_narr.tokens()[:20] # preview tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['SUB'])\n",
      "dict_keys(['SUB', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n",
      "dict_keys(['PAR', 'INV'])\n"
     ]
    }
   ],
   "source": [
    "for p in BELC_narr.headers():\n",
    "    print(p['Participants'].keys()) # checking keys to access data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating empty lists\n",
    "file_path_list = []\n",
    "participant_list = []\n",
    "age_list = []\n",
    "group_list = []\n",
    "corpus_list = []\n",
    "tokens_list = []\n",
    "\n",
    "# read entire corpus into a Reader object\n",
    "BELCcorpus = pylangacq.read_chat(path, 'narratives')\n",
    "for f in BELCcorpus:\n",
    "    file_path = f.file_paths()[0].split('/')[3]\n",
    "    participant = f.headers()[0]['PID']\n",
    "    if 'SUB' in f.headers()[0]['Participants']:\n",
    "        age = f.headers()[0]['Participants']['SUB']['age']\n",
    "        group = f.headers()[0]['Participants']['SUB']['group']\n",
    "        corpus = f.headers()[0]['Participants']['SUB']['corpus']\n",
    "    elif 'PAR' in f.headers()[0]['Participants']:\n",
    "        age = f.headers()[0]['Participants']['PAR']['age']\n",
    "        group = f.headers()[0]['Participants']['PAR']['group']\n",
    "        corpus = f.headers()[0]['Participants']['PAR']['corpus']\n",
    "    tokens = f.tokens()\n",
    "    # appending values to lists\n",
    "    file_path_list.append(file_path)\n",
    "    participant_list.append(participant)\n",
    "    age_list.append(age)\n",
    "    group_list.append(group)\n",
    "    corpus_list.append(corpus)\n",
    "    tokens_list.append(tokens)\n",
    "    \n",
    "# repeating this process with an additional folder\n",
    "BELCcorpus = pylangacq.read_chat(path, 'narratives-2014')\n",
    "for f in BELCcorpus:\n",
    "    file_path = f.file_paths()[0].split('/')[3]\n",
    "    participant = f.headers()[0]['PID']\n",
    "    if 'SUB' in f.headers()[0]['Participants']:\n",
    "        age = f.headers()[0]['Participants']['SUB']['age']\n",
    "        group = f.headers()[0]['Participants']['SUB']['group']\n",
    "        corpus = f.headers()[0]['Participants']['SUB']['corpus']\n",
    "    elif 'PAR' in f.headers()[0]['Participants']:\n",
    "        age = f.headers()[0]['Participants']['PAR']['age']\n",
    "        group = f.headers()[0]['Participants']['PAR']['group']\n",
    "        corpus = f.headers()[0]['Participants']['PAR']['corpus']\n",
    "    tokens = f.tokens()\n",
    "    # appending values to lists\n",
    "    file_path_list.append(file_path)\n",
    "    participant_list.append(participant)\n",
    "    age_list.append(age)\n",
    "    group_list.append(group)\n",
    "    corpus_list.append(corpus)\n",
    "    tokens_list.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the dataframe\n",
    "BELCcorpus_df = pd.DataFrame({'Filename':file_path_list,\n",
    "                              'Corpus':corpus_list,\n",
    "                            'Participant':participant_list,\n",
    "                             'Age':age_list,\n",
    "                             'Group':group_list,\n",
    "                             'Tokens':tokens_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Group</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BELC\\narratives-2014\\time1time2\\9139riza_1.cha</td>\n",
       "      <td>BELC</td>\n",
       "      <td>11312/t-00016825-1</td>\n",
       "      <td>10;09.00</td>\n",
       "      <td>1A</td>\n",
       "      <td>[Token(word='okay', pos='co', mor='okay', gra=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BELC\\narratives-2014\\time1time2\\9139riza_2.cha</td>\n",
       "      <td>BELC</td>\n",
       "      <td>11312/t-00016826-1</td>\n",
       "      <td></td>\n",
       "      <td>EL</td>\n",
       "      <td>[Token(word='Rita', pos='n:prop', mor='Rita', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BELC\\narratives-2014\\time1time2\\9144nugo_1.cha</td>\n",
       "      <td>BELC</td>\n",
       "      <td>11312/t-00016827-1</td>\n",
       "      <td>10;09.</td>\n",
       "      <td></td>\n",
       "      <td>[Token(word='okay', pos='co', mor='okay', gra=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BELC\\narratives-2014\\time1time2\\9144nugo_2.cha</td>\n",
       "      <td>BELC</td>\n",
       "      <td>11312/t-00016828-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Token(word='Núria', pos='n:prop', mor='Núria'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BELC\\narratives-2014\\time1time2\\9148mira_1.cha</td>\n",
       "      <td>BELC</td>\n",
       "      <td>11312/t-00016829-1</td>\n",
       "      <td>17;09.00</td>\n",
       "      <td>4A</td>\n",
       "      <td>[Token(word='okay', pos='co', mor='okay', gra=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Filename Corpus         Participant  \\\n",
       "0  BELC\\narratives-2014\\time1time2\\9139riza_1.cha   BELC  11312/t-00016825-1   \n",
       "1  BELC\\narratives-2014\\time1time2\\9139riza_2.cha   BELC  11312/t-00016826-1   \n",
       "2  BELC\\narratives-2014\\time1time2\\9144nugo_1.cha   BELC  11312/t-00016827-1   \n",
       "3  BELC\\narratives-2014\\time1time2\\9144nugo_2.cha   BELC  11312/t-00016828-1   \n",
       "4  BELC\\narratives-2014\\time1time2\\9148mira_1.cha   BELC  11312/t-00016829-1   \n",
       "\n",
       "        Age Group                                             Tokens  \n",
       "0  10;09.00    1A  [Token(word='okay', pos='co', mor='okay', gra=...  \n",
       "1              EL  [Token(word='Rita', pos='n:prop', mor='Rita', ...  \n",
       "2    10;09.        [Token(word='okay', pos='co', mor='okay', gra=...  \n",
       "3                  [Token(word='Núria', pos='n:prop', mor='Núria'...  \n",
       "4  17;09.00    4A  [Token(word='okay', pos='co', mor='okay', gra=...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BELCcorpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe of two narrative speaking tasks from the BELC corpus is constructed. Let's make sure it is tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Filename     210 non-null    object\n",
      " 1   Corpus       210 non-null    object\n",
      " 2   Participant  210 non-null    object\n",
      " 3   Age          210 non-null    object\n",
      " 4   Group        210 non-null    object\n",
      " 5   Tokens       210 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "BELCcorpus_df.info() # says there are no null values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      52\n",
       "2A    37\n",
       "1A    27\n",
       "3A    26\n",
       "4A    21\n",
       "EL    16\n",
       "LL    10\n",
       "1B    10\n",
       "2B    10\n",
       "2      1\n",
       "Name: Group, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BELCcorpus_df.Group.value_counts() # but the group variable looks funky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These group names don't correlate to the description on the BELC corpus website on TalkBank. I will have to look into this further to make sense of it in order to calculate the learners' years studying English. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELC contains data from Spanish and Catalan speakers. Let's import more data from additional corpus to represent a variety of L1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
